{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cbe3b1-0c7b-4364-98c1-3b133bdac5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# x = '/home/amax/yyq/Dataset/CDnet2014/change_dataset/badWeather/blizzard/'\n",
    "# print(len(os.listdir(x+'/total/time1/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d969a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sys\n",
    "import matplotlib as mpl \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm as tqdmm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from IPython.display import HTML, display,clear_output\n",
    "from collections import Counter\n",
    "\n",
    "import Utils.Dataload as d\n",
    "\n",
    "# part = 'shadow/'\n",
    "# subpart = 'copyMachine/'\n",
    "\n",
    "part = 'baseline/'\n",
    "subpart = 'office/'\n",
    "\n",
    "# part = 'cameraJitter/'\n",
    "# subpart = 'badminton/'\n",
    "\n",
    "# part = 'badWeather/'\n",
    "# subpart = 'blizzard/'\n",
    "\n",
    "Dataset_store = 'Run_logging/cdnet/'\n",
    "if 1-os.path.exists(Dataset_store+part):\n",
    "    os.mkdir(Dataset_store+part)\n",
    "if 1-os.path.exists(Dataset_store+part+subpart):\n",
    "    os.mkdir(Dataset_store+part+subpart)\n",
    "    \n",
    "Dataset_name = Dataset_store+part+subpart\n",
    "DATA_PATH = '/home/amax/yyq/Dataset/CDnet2014/change_dataset/'+part+subpart\n",
    "t_label_path = DATA_PATH+'/total/t_label/'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,0'\n",
    "device1 = torch.device(\"cuda:0\")\n",
    "device0 = torch.device(\"cuda:1\")\n",
    "device2 = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef862d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH)\n",
    "TRAIN_LABEL_PATH = os.path.join(DATA_PATH)\n",
    "TRAIN_TXT_PATH = os.path.join(TRAIN_DATA_PATH,'train.txt')\n",
    "TEST_DATA_PATH = os.path.join(DATA_PATH)\n",
    "TEST_LABEL_PATH = os.path.join(DATA_PATH)\n",
    "TEST_TXT_PATH = os.path.join(TEST_DATA_PATH, 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813aa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 2\n",
    "test_batch_size = val_batch_size = 2\n",
    "\n",
    "train_data = d.Dataset(TRAIN_DATA_PATH, TRAIN_LABEL_PATH,\n",
    "                            TRAIN_TXT_PATH,'train',transform=True)\n",
    "train_loader = DataLoader(train_data, batch_size=train_batch_size,\n",
    "                             shuffle= True, num_workers= 8, pin_memory= True)\n",
    "test_data = d.Dataset(TEST_DATA_PATH, TEST_LABEL_PATH,\n",
    "                        TEST_TXT_PATH,'test', transform=False)\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch_size,\n",
    "                            shuffle= False, num_workers= 8, pin_memory= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17d7746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I1 = torch.from_numpy(test_data[0][0]).unsqueeze(0)\n",
    "# I2 = torch.from_numpy(test_data[0][1]).unsqueeze(0)\n",
    "\n",
    "# plt.imshow(I2[0].permute(1,2,0)+0.5)\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(I1[0].permute(1,2,0)+0.5)\n",
    "# plt.show()\n",
    "\n",
    "# prediction = model(I1,I2)\n",
    "\n",
    "# plt.imshow((prediction[0].permute(1,2,0)).detach().numpy()[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1335f6bc-28b5-4d26-9852-5f09d1f1a332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(x,**kwargs):\n",
    "    plt.figure(dpi=100)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x,**kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8dea325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(data_loader):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Accuracies = []\n",
    "        Right = 0\n",
    "        Sum = 0\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "\n",
    "        for i,(i1,i2,label,file_name,mask) in enumerate(tqdm(data_loader)):\n",
    "            i1,i2,label = i1.cuda(),i2.cuda(),label.cuda()\n",
    "\n",
    "            prediction,c1,c2 = model(i1,i2)\n",
    "            prediction = (prediction>0.5).int()\n",
    "\n",
    "            Right += torch.sum(prediction == label)\n",
    "            Sum += torch.sum(label>-1)\n",
    "\n",
    "            impred = prediction\n",
    "            imlabel = label\n",
    "\n",
    "            accuracy = OA(prediction.view(-1),label.view(-1))\n",
    "            Accuracies.append(float(accuracy))\n",
    "\n",
    "            #Precision,recall,Iou\n",
    "            numclass = 1\n",
    "            TP +=  int(torch.sum(impred * (impred == imlabel)))\n",
    "            FP += int(torch.sum(impred * (impred != imlabel)))\n",
    "            FN += int(torch.sum(imlabel * (impred != imlabel)))\n",
    "\n",
    "        Average_accuracy = np.mean(Accuracies)\n",
    "        Overrall_accuracy = float(Right/Sum)\n",
    "        Iou = TP/(TP+FP+FN)\n",
    "        Percison = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = (2*Percison*Recall)/(Percison+Recall)\n",
    "\n",
    "        Average_accuracy = round(Average_accuracy,4)\n",
    "        Overrall_accuracy = round(Overrall_accuracy,4)\n",
    "        Iou = round(Iou,4)\n",
    "        Percison = round(Percison,4)\n",
    "        Recall = round(Recall,4)\n",
    "        F1 = round(F1,4)\n",
    "\n",
    "        print('AA: \\t\\t',Average_accuracy)\n",
    "        print('OA:\\t\\t',Overrall_accuracy)\n",
    "        print('Iou:\\t\\t',Iou)\n",
    "        print('Percison:\\t',Percison)\n",
    "        print('Recall:\\t\\t',Recall)\n",
    "        print('F1\\t\\t',F1)\n",
    "    \n",
    "    f = open(Log_path+'Metric_recording.txt','a')\n",
    "    f.write('Epoch:'+str(epoch)+'   Currentoa:'+str(round(F1,4))+'   Bestoa:'+str(round(best_acc,4))+'\\n')\n",
    "    f.close()\n",
    "    state_dict = Load_Weight_FordataParallel(model.state_dict(),need_dataparallel=0)\n",
    "    torch.save(state_dict, Log_path+'Last_model.pth')\n",
    "    \n",
    "    if F1 >= best_acc:\n",
    "        best_acc = F1\n",
    "        state_dict = Load_Weight_FordataParallel(model.state_dict(),need_dataparallel=0)\n",
    "        torch.save(state_dict, Log_path+'Best_model.pth')\n",
    "        f = open(Log_path+'Metric_recording.txt','a')\n",
    "        f.write('The details of performance: \\n')\n",
    "        f.write('AA: \\t\\t'+str(Average_accuracy)+'\\n'+'OA:\\t\\t'+str(Overrall_accuracy)+'\\n'+'Iou:\\t\\t'+str(Iou)+'\\n'+'Percison:\\t'+str(Percison)+'\\n'+'Recall:\\t\\t'+str(Recall)+'\\n'+'F1\\t\\t'+str(F1)+'\\n\\n')\n",
    "        f.close()\n",
    "    \n",
    "def eval_model():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Accuracies = []\n",
    "        Right = 0\n",
    "        Sum = 0\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "\n",
    "        for i,(i1,i2,label,file_name,mask) in enumerate(tqdm(test_loader)):\n",
    "            i1,i2,label = i1.cuda(),i2.cuda(),label.cuda()\n",
    "\n",
    "            prediction,c1,c2 = model(i1,i2)\n",
    "            prediction = (prediction>0.5).int()\n",
    "    #             plt.imsave('vis_'+Dataset+'/'+filename[0].split('/')[-1].split('.')[0]+'.png',prediction[0].cpu(),cmap='gray')\n",
    "\n",
    "            Right += torch.sum(prediction == label)\n",
    "            Sum += torch.sum(label>-1)\n",
    "\n",
    "            impred = prediction\n",
    "            imlabel = label\n",
    "\n",
    "            accuracy = OA(prediction.view(-1),label.view(-1))\n",
    "            Accuracies.append(float(accuracy))\n",
    "\n",
    "            #Precision,recall,Iou\n",
    "            TP +=  int(torch.sum(impred * (impred == imlabel)))\n",
    "            FP += int(torch.sum(impred * (impred != imlabel)))\n",
    "            FN += int(torch.sum(imlabel * (impred != imlabel)))\n",
    "\n",
    "        Average_accuracy = np.mean(Accuracies)\n",
    "        Overrall_accuracy = float(Right/Sum)\n",
    "        Iou = TP/(TP+FP+FN)\n",
    "        Percison = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = (2*Percison*Recall)/(Percison+Recall)\n",
    "\n",
    "        Average_accuracy = round(Average_accuracy,4)\n",
    "        Overrall_accuracy = round(Overrall_accuracy,4)\n",
    "        Iou = round(Iou,4)\n",
    "        Percison = round(Percison,4)\n",
    "        Recall = round(Recall,4)\n",
    "        F1 = round(F1,4)\n",
    "\n",
    "    print('AA: \\t\\t',Average_accuracy)\n",
    "    print('OA:\\t\\t',Overrall_accuracy)\n",
    "    print('Iou:\\t\\t',Iou)\n",
    "    print('Percison:\\t',Percison)\n",
    "    print('Recall:\\t\\t',Recall)\n",
    "    print('F1\\t\\t',F1)\n",
    "    \n",
    "def trend_test():\n",
    "    test_data = d.Dataset(TEST_DATA_PATH, TEST_LABEL_PATH,\n",
    "                            TEST_TXT_PATH,'test', transform=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=1,\n",
    "                                shuffle= False, num_workers= 8, pin_memory= True)\n",
    "\n",
    "    TPs = [0,0,0]\n",
    "    FPs = [0,0,0]\n",
    "    FNs = [0,0,0]\n",
    "    Ts = [0,0,0]\n",
    "    Sums = [0,0,0]\n",
    "\n",
    "    model.eval()\n",
    "    for iter_, (i1,i2,label,file_name,mask) in enumerate(tqdm(test_loader)):\n",
    "        i1,i2,label = i1.cuda(),i2.cuda(),label.cuda()\n",
    "        with torch.no_grad():\n",
    "            p,c1,c2 = model(i1,i2)\n",
    "            c1_,c2_ = torch.max(c1,dim=1)[1],torch.max(c2,dim=1)[1]\n",
    "            t1_semantic, t2_semantic = c1_[0], c2_[0]\n",
    "            appear = ((t2_semantic-t1_semantic)==t2_semantic)*(t2_semantic!=0).int()\n",
    "            disappear = ((t1_semantic-t2_semantic)==t1_semantic)*(t1_semantic!=0).int()\n",
    "            transform = ((t2_semantic!=0).int())*((t1_semantic!=0).int())\n",
    "            trend_map = (appear+disappear*2+transform*3).cpu()\n",
    "\n",
    "            trend_name = file_name[0].split('/')[-1].split('.')[0]+'.npy'\n",
    "            label_trend_path = os.path.join(t_label_path,trend_name)\n",
    "            label_trend = torch.tensor(np.load(label_trend_path))\n",
    "\n",
    "            for i,value in enumerate([1,2,3]):\n",
    "                trend_map_i = (trend_map==value).int()\n",
    "                label_trend_i = (label_trend==value).int()\n",
    "                TPs[i]+= int(torch.sum(trend_map_i * (trend_map_i == label_trend_i)))\n",
    "                FPs[i]+= int(torch.sum(trend_map_i * (trend_map_i != label_trend_i)))\n",
    "                FNs[i]+= int(torch.sum(label_trend_i * (trend_map_i != label_trend_i)))\n",
    "                Ts[i] += int(torch.sum(trend_map_i == label_trend_i))\n",
    "                Sums[i]+=int(torch.sum(trend_map_i >-1))\n",
    "    OAs = []\n",
    "    IoUs = []\n",
    "    Ps = []\n",
    "    Rs = []\n",
    "    F1s = []\n",
    "    for i in range(3):\n",
    "        TP = TPs[i]\n",
    "        FP = FPs[i]\n",
    "        FN = FNs[i]\n",
    "        OAs.append(Ts[i]/Sums[i])\n",
    "        IoUs.append(TP/(TP+FP+FN))\n",
    "        p = TP/(TP+FP)\n",
    "        r = TP/(TP+FN)\n",
    "        Ps.append(p)\n",
    "        Rs.append(r)\n",
    "        F1s.append((2*p*r)/(p+r))\n",
    "    f = open(Log_path+'Final_performance.txt','a')\n",
    "    f.write('OA:'+str(OAs)+'\\nIoU:'+str(IoUs)+'\\nPrecision:'+str(Ps)+'\\nRecall:'+str(Rs)+'\\nF1:'+str(F1s)+'\\n')\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    print(Ps)\n",
    "    print(Rs)\n",
    "    print(F1s)\n",
    "    print(IoUs)\n",
    "    print(OAs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ca6dd5-a308-492b-b14a-238bf96fd03e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch\n",
    "\n",
    "def OA(pre_classes, gt_classes):\n",
    "    return torch.sum((pre_classes) == (gt_classes)).float()/len(pre_classes)\n",
    "\n",
    "def T_softmax(x,dim=1,T=0.1):\n",
    "    x = x/T\n",
    "    x_ = torch.exp(x)\n",
    "    x = x_/torch.sum(x_,dim=1).unsqueeze(dim)\n",
    "    return x\n",
    "\n",
    "from collections import OrderedDict\n",
    "def Load_Weight_FordataParallel(state_dict, need_dataparallel=0):\n",
    "        if_dataparallel = 1\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[:6]\n",
    "            if name != \"module\":\n",
    "                if_dataparallel = 0\n",
    "        if need_dataparallel == 1:\n",
    "            if if_dataparallel == 1:\n",
    "                return state_dict\n",
    "            else:\n",
    "                new_state_dict = OrderedDict()\n",
    "                for k, v in state_dict.items():\n",
    "                    name = \"module.\"+k \n",
    "                    new_state_dict[name] = v \n",
    "                return new_state_dict\n",
    "        else:\n",
    "            if if_dataparallel == 0:\n",
    "                return state_dict\n",
    "            else:\n",
    "                new_state_dict = OrderedDict()\n",
    "                for k, v in state_dict.items():\n",
    "                    name = k[7:] \n",
    "                    new_state_dict[name] = v \n",
    "                return new_state_dict \n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution Block \n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_block, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    Up Convolution Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, size=None):\n",
    "        if size is not None:\n",
    "            x = nn.Upsample(size=size, mode='bilinear')(x)\n",
    "        else:\n",
    "            x = nn.Upsample(scale_factor=2, mode='bilinear')(x)\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet - Basic Implementation\n",
    "    Paper : https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, nl=32):\n",
    "        super(UNet_Encoder, self).__init__()\n",
    "\n",
    "        n1 = nl\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "        \n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(in_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "    def forward(self, x):\n",
    "        es = {}\n",
    "        \n",
    "        e1 = self.Conv1(x)\n",
    "        es['e1']=e1\n",
    "        \n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "        es['e2']=e2\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "        es['e3']=e3\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "        es['e4']=e4\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "        es['e5']=e5\n",
    "\n",
    "        return es\n",
    "\n",
    "class UNet_Decoder_I(nn.Module):\n",
    "    def __init__(self, out_ch=2, nl = 64):\n",
    "        super(UNet_Decoder_I, self).__init__()\n",
    "\n",
    "        n1 = nl\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "        \n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "    def forward(self, e):\n",
    "        e5 = e['e5']\n",
    "        e4 = e['e4']\n",
    "        e3 = e['e3']\n",
    "        e2 = e['e2']\n",
    "        e1 = e['e1']\n",
    "        \n",
    "        d5 = self.Up5(e5,size=e4.shape[2:])\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5,size=e3.shape[2:])\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4,size=e2.shape[2:])\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3,size=e1.shape[2:])\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        return d2\n",
    "\n",
    "\n",
    "class UNet_Decoder_S(nn.Module):\n",
    "    def __init__(self, out_ch=2, nl = 128):\n",
    "        super(UNet_Decoder_S, self).__init__()\n",
    "\n",
    "        n1 = nl\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "        \n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "    def forward(self, t1_e, t2_e):\n",
    "        e5 = torch.cat((t1_e['e5'], t2_e['e5']),dim=1)\n",
    "        e4 = torch.cat((t1_e['e4'], t2_e['e4']),dim=1)\n",
    "        e3 = torch.cat((t1_e['e3'], t2_e['e3']),dim=1)\n",
    "        e2 = torch.cat((t1_e['e2'], t2_e['e2']),dim=1)\n",
    "        e1 = torch.cat((t1_e['e1'], t2_e['e1']),dim=1)\n",
    "        \n",
    "        d5 = self.Up5(e5,size=e4.shape[2:])\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5,size=e3.shape[2:])\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4,size=e2.shape[2:])\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3,size=e1.shape[2:])\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        return d2\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=2, nl=64, trend_num = 3, T=0.1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = UNet_Encoder(in_ch,nl)\n",
    "        self.decoder_s = UNet_Decoder_S(out_ch,nl=nl*2)\n",
    "        self.decoder_i = UNet_Decoder_I(out_ch,nl=nl)\n",
    "        self.conv_s1 = nn.Conv2d(nl+nl*2, trend_num, kernel_size=1)\n",
    "        self.conv_s2 = nn.Conv2d(nl+nl*2, trend_num, kernel_size=1)\n",
    "        self.conv_i1 = nn.Conv2d(nl, trend_num, kernel_size=1)\n",
    "        self.conv_i2 = nn.Conv2d(nl, trend_num, kernel_size=1)\n",
    "        self.T = T\n",
    "    def Normalization(self, x,dim=1):\n",
    "        min_ = torch.min(x,dim=dim)[0].unsqueeze(dim)\n",
    "        max_ = torch.max(x,dim=dim)[0].unsqueeze(dim)\n",
    "        x = (x-min_)/(max_-min_)\n",
    "        return x\n",
    "\n",
    "    def forward(self, t1_i,t2_i):\n",
    "        t1_f = self.encoder(t1_i)\n",
    "        t2_f = self.encoder(t2_i)\n",
    "        \n",
    "        t1_s = self.decoder_i(t1_f)\n",
    "        t2_s = self.decoder_i(t2_f)\n",
    "        s = self.decoder_s(t1_f,t2_f)\n",
    "        \n",
    "        t1_trend_ = self.conv_s1(torch.cat((s,t1_s),dim=1))\n",
    "        t2_trend_ = self.conv_s2(torch.cat((s,t2_s),dim=1))\n",
    "        t1_trend_ = t1_trend_ - torch.max(t1_trend_,dim=1)[0].unsqueeze(1)\n",
    "        t2_trend_ = t2_trend_ - torch.max(t2_trend_,dim=1)[0].unsqueeze(1)\n",
    "#         t1_trend_ = self.Normalization(t1_trend_,dim=1)-0.9\n",
    "#         t2_trend_ = self.Normalization(t2_trend_,dim=1)-0.9\n",
    "        t1_trend = T_softmax(t1_trend_,dim=1,T=self.T)\n",
    "        t2_trend = T_softmax(t2_trend_,dim=1,T=self.T)\n",
    "        \n",
    "        p = 1-torch.sum(t1_trend*t2_trend,dim=1)\n",
    "        \n",
    "        t1_trend_ = self.conv_i1(t1_s)\n",
    "        t2_trend_ = self.conv_i2(t2_s)\n",
    "        t1_trend_ = t1_trend_ - torch.max(t1_trend_,dim=1)[0].unsqueeze(1)\n",
    "        t2_trend_ = t2_trend_ - torch.max(t2_trend_,dim=1)[0].unsqueeze(1)\n",
    "#         t1_trend_ = self.Normalization(t1_trend_,dim=1)-0.9\n",
    "#         t2_trend_ = self.Normalization(t2_trend_,dim=1)-0.9\n",
    "        t1_trend = T_softmax(t1_trend_,dim=1,T=self.T)\n",
    "        t2_trend = T_softmax(t2_trend_,dim=1,T=self.T)\n",
    "        \n",
    "        return p, t1_trend, t2_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3fa2e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_num = 99\n",
    "trend_num = 3\n",
    "best_acc = 0\n",
    "loss_mean = []\n",
    "# pretrained_path = Dataset_name+'/Best_model-Copy1.pth'\n",
    "pretrained_path = None\n",
    "# \n",
    "Log_path = Dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344c5d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = UNet(3,2,trend_num=trend_num)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "\n",
    "if pretrained_path is not None:\n",
    "    state_dict = Load_Weight_FordataParallel(torch.load(pretrained_path),need_dataparallel=1)\n",
    "#     model.load_state_dict(state_dict)\n",
    "    pretrain_state_dict = {}\n",
    "    for k,v in model.state_dict().items():\n",
    "        if k in state_dict.keys():\n",
    "            pretrain_state_dict[k] = state_dict[k]\n",
    "        else:\n",
    "            pretrain_state_dict[k] = v\n",
    "    model.load_state_dict(pretrain_state_dict)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "STEPS_PER_EPOCH = len(train_loader)\n",
    "TOTAL_STEPS = STEPS_PER_EPOCH * 80\n",
    "scheduler = lr_scheduler.StepLR(opt, step_size=TOTAL_STEPS, gamma=0.1)\n",
    "\n",
    "Loss_function_classify = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27e384c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_p_n(p,label, weight=None):\n",
    "    loss_p = torch.mean(-label*torch.log(p+1e-10),dim=(1,2))\n",
    "    loss_n = torch.mean(-(1-label)*torch.log(1-p+1e-10),dim=(1,2))\n",
    "    if weight is not None:\n",
    "        loss = loss_p*(1-weight) + loss_n*weight\n",
    "    else:\n",
    "        loss = loss_p+loss_n\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def loss_p(p,label,weight=None):\n",
    "    loss_p = torch.mean(-label*torch.log(p+1e-10),dim=(1,2))\n",
    "    if weight is not None:\n",
    "        loss_p = loss_p*weight\n",
    "    return torch.mean(loss_p)\n",
    "\n",
    "def sigmoid_coe(x,T=0.01):\n",
    "    y = 1/(1+torch.exp((-x+0.5)/T))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f778f28-ee27-4dd0-8e36-12c290066c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b22798cb4e410eaa13b7987ac8a270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_10235/829674244.py\", line 243, in forward\n    s = self.decoder_s(t1_f,t2_f)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_10235/829674244.py\", line 216, in forward\n    d2 = self.Up_conv2(d2)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_10235/829674244.py\", line 58, in forward\n    x = self.conv(x)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n    input = module(input)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 135, in forward\n    return F.batch_norm(\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/functional.py\", line 2146, in batch_norm\n    return torch.batch_norm(\nRuntimeError: CUDA out of memory. Tried to allocate 176.00 MiB (GPU 0; 23.70 GiB total capacity; 8.56 GiB already allocated; 126.56 MiB free; 8.66 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_, (i1,i2,label,file_name,mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m      9\u001b[0m     i1,i2,label \u001b[38;5;241m=\u001b[39m i1\u001b[38;5;241m.\u001b[39mcuda(),i2\u001b[38;5;241m.\u001b[39mcuda(),label\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 10\u001b[0m     p,c1,c2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     nc1, nc2 \u001b[38;5;241m=\u001b[39m c1[:,\u001b[38;5;241m0\u001b[39m],c2[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(label,dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m/\u001b[39m(label\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mlabel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:167\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    166\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 167\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:177\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/_utils.py:429\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# Some exceptions have first argument as non-str but explicitly\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# have message field\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(message\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(msg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_10235/829674244.py\", line 243, in forward\n    s = self.decoder_s(t1_f,t2_f)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_10235/829674244.py\", line 216, in forward\n    d2 = self.Up_conv2(d2)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_10235/829674244.py\", line 58, in forward\n    x = self.conv(x)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n    input = module(input)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 135, in forward\n    return F.batch_norm(\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/functional.py\", line 2146, in batch_norm\n    return torch.batch_norm(\nRuntimeError: CUDA out of memory. Tried to allocate 176.00 MiB (GPU 0; 23.70 GiB total capacity; 8.56 GiB already allocated; 126.56 MiB free; 8.66 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "loss_sum = []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    loss_mean = []\n",
    "    \n",
    "    loss_mean_1 = []\n",
    "    loss_mean_2 = []\n",
    "    for iter_, (i1,i2,label,file_name,mask) in enumerate(tqdm(train_loader)):\n",
    "        i1,i2,label = i1.cuda(),i2.cuda(),label.cuda()\n",
    "        p,c1,c2 = model(i1,i2)\n",
    "        nc1, nc2 = c1[:,0],c2[:,0]\n",
    "        ratio = torch.sum(label,dim=(1,2))/(label.shape[1]*label.shape[2])\n",
    "\n",
    "        loss1 = loss_p_n(p,label)\n",
    "        \n",
    "        loss2_n = loss_p(nc1*nc2, (1-label))\n",
    "        loss2_g = loss_p_n(1-torch.sum(c1*c2,dim=1),label)\n",
    "        loss2 = loss2_n+loss2_g\n",
    "\n",
    "        loss = (loss1+loss2)*10\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        loss_mean.append(loss.item())\n",
    "        loss_mean_1.append(loss1.item())\n",
    "        loss_mean_2.append(loss2.item())\n",
    "                \n",
    "        if (iter_+1)%10 ==0:\n",
    "            print('******************')\n",
    "            print()\n",
    "            print('Total loss: ',round(np.mean(loss_mean),5))\n",
    "            print('Change loss: ',round(np.mean(loss_mean_1),5))\n",
    "            print('Trend loss: ',round(np.mean(loss_mean_2),5))\n",
    "            print('******************')\n",
    "            loss_sum.append(np.mean(loss_mean))\n",
    "            loss_mean = []\n",
    "            loss_mean_1 = []\n",
    "            loss_mean_2 = []\n",
    "            loss_mean_3 = []\n",
    "    try:\n",
    "        trend_test()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a796da4-3c3d-4a06-bf3f-501811daaea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d18261-16dd-4601-ba41-a773b7c2aec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80394c2d-bba2-4f4f-8ffd-4d5686b8502c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d51ba6-36ce-4eea-9d6e-139fd43e4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "FCN\n",
    "[0.8973379405594588, 0.9080061283664864, 0.9703206541059367]\n",
    "[0.8108292403908425, 0.8314716174318756, 0.8185130985510027]\n",
    "[0.8518930100424145, 0.8680551688741801, 0.8879753794902826]\n",
    "[0.7419979300656344, 0.7668705620669005, 0.7985213304749155]\n",
    "[0.9892141384548611, 0.9901437717013889, 0.9922158022280093]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc159e-a253-486e-be86-dfc7fad883be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deeplabv3\n",
    "[0.9112068580898053, 0.91408862799065, 0.9647387046899158]\n",
    "[0.8447679667963487, 0.8610333624745787, 0.8420113232895116]\n",
    "[0.8767305247548979, 0.886768131076207, 0.8992067533249429]\n",
    "[0.7805166472307027, 0.7965709173718519, 0.8168716114865298]\n",
    "[0.9909121365017362, 0.9914257360387732, 0.9928851544415509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653ed12-4b43-43d1-8272-bcea648fef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "SegNeXt\n",
    "[0.9196189652541079, 0.9130594526428112, 0.9724873889680886]\n",
    "[0.8545283937544612, 0.8730674600505991, 0.8509847903272239]\n",
    "[0.8858796460784144, 0.8926157391491955, 0.9076880757420676]\n",
    "[0.7951381939663988, 0.8060578163386554, 0.8309788216939131]\n",
    "[0.9915773292824074, 0.9918089011863426, 0.993475929542824]\n",
    "\n",
    "\n",
    "[0.9570197078991061, 0.9236653458872596, 0.8688452366949325]\n",
    "[0.844006892215767, 0.848423010298377, 0.9746161596775741]\n",
    "[0.8969675732736505, 0.8844467946877785, 0.9186963281227916]\n",
    "[0.813183322212683, 0.7928324623837545, 0.8496191699117043]\n",
    "[0.9925821487991898, 0.9913554777922454, 0.9934979926215278]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1f8b0-453b-4ccb-9bca-e7156843b3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bcf58-131c-452b-ad05-5f70a5b8bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Transform           Appear            Disappear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299503b2-89dd-4a91-ac83-47acd5da3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.8973379405594588, 0.9080061283664864, 0.9703206541059367]\n",
    "[0.9112068580898053, 0.91408862799065, 0.9647387046899158]\n",
    "[0.9196189652541079, 0.9130594526428112, 0.9724873889680886]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d222fc9-6b79-403e-9f2a-c59630db0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.8108292403908425, 0.8314716174318756, 0.8185130985510027]\n",
    "[0.8447679667963487, 0.8610333624745787, 0.8420113232895116]\n",
    "[0.8545283937544612, 0.8730674600505991, 0.8509847903272239]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019549d-dfe3-479e-9f79-ea27c909c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.8518930100424145, 0.8680551688741801, 0.8879753794902826]\n",
    "[0.8767305247548979, 0.886768131076207, 0.8992067533249429]\n",
    "[0.8858796460784144, 0.8926157391491955, 0.9076880757420676]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4ce46-4b82-4d86-b997-868699694828",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.7419979300656344, 0.7668705620669005, 0.7985213304749155]\n",
    "[0.7805166472307027, 0.7965709173718519, 0.8168716114865298]\n",
    "[0.7951381939663988, 0.8060578163386554, 0.8309788216939131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebe4f7-7b7b-44d0-9293-8db19b270a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.9892141384548611, 0.9901437717013889, 0.9922158022280093]\n",
    "[0.9909121365017362, 0.9914257360387732, 0.9928851544415509]\n",
    "[0.9915773292824074, 0.9918089011863426, 0.993475929542824]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982885f-eead-49f4-aade-26e04a67a3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88c3d8-c620-4281-b3cb-1da0af631bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272d8a8-909d-4c1c-b010-bf52901e2434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ceacb1-9bda-44bc-9c21-985a3de7d02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce82ee-1c4d-4a5a-8632-fb2fe30a0e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42904047-e93e-4257-b542-740f2a703ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888cf82-568b-4bda-903b-46820caae7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35248c0-cf02-4148-a336-591f155a4472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cbad13-a78c-4abf-bc90-64a0cd75dc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936f494-1976-4405-a9a1-ee1fea1a8cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbdff9-dfe2-4c4f-a9c9-904d6fbeb55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c15ea-23b0-4b06-8eff-6947ff3a49a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8144373-7d31-49e3-9851-30cfcd94b5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6530d22e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884cbe96eb414a8d8dbebeacaa7726d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_41896/829674244.py\", line 241, in forward\n    t1_s = self.decoder_i(t1_f)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_41896/829674244.py\", line 160, in forward\n    d4 = self.Up4(d5,size=e3.shape[2:])\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_41896/829674244.py\", line 79, in forward\n    x = self.up(x)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n    input = module(input)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 135, in forward\n    return F.batch_norm(\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/functional.py\", line 2146, in batch_norm\n    return torch.batch_norm(\nRuntimeError: CUDA out of memory. Tried to allocate 44.00 MiB (GPU 0; 23.70 GiB total capacity; 22.22 GiB already allocated; 6.56 MiB free; 22.36 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_, (i1,i2,label,file_name,mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m      9\u001b[0m     i1,i2,label \u001b[38;5;241m=\u001b[39m i1\u001b[38;5;241m.\u001b[39mcuda(),i2\u001b[38;5;241m.\u001b[39mcuda(),label\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 10\u001b[0m     p,c1,c2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     nc1, nc2 \u001b[38;5;241m=\u001b[39m c1[:,\u001b[38;5;241m0\u001b[39m],c2[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(label,dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m/\u001b[39m(label\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mlabel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:167\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    166\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 167\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:177\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/_utils.py:429\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# Some exceptions have first argument as non-str but explicitly\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# have message field\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(message\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(msg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_41896/829674244.py\", line 241, in forward\n    t1_s = self.decoder_i(t1_f)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_41896/829674244.py\", line 160, in forward\n    d4 = self.Up4(d5,size=e3.shape[2:])\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/tmp/ipykernel_41896/829674244.py\", line 79, in forward\n    x = self.up(x)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n    input = module(input)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 135, in forward\n    return F.batch_norm(\n  File \"/home/amax/anaconda3/envs/bakpy38/lib/python3.8/site-packages/torch/nn/functional.py\", line 2146, in batch_norm\n    return torch.batch_norm(\nRuntimeError: CUDA out of memory. Tried to allocate 44.00 MiB (GPU 0; 23.70 GiB total capacity; 22.22 GiB already allocated; 6.56 MiB free; 22.36 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "loss_sum = []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    loss_mean = []\n",
    "    \n",
    "    loss_mean_1 = []\n",
    "    loss_mean_2 = []\n",
    "    for iter_, (i1,i2,label,file_name,mask) in enumerate(tqdm(train_loader)):\n",
    "        i1,i2,label = i1.cuda(),i2.cuda(),label.cuda()\n",
    "        p,c1,c2 = model(i1,i2)\n",
    "        nc1, nc2 = c1[:,0],c2[:,0]\n",
    "        ratio = torch.sum(label,dim=(1,2))/(label.shape[1]*label.shape[2])\n",
    "\n",
    "        loss1 = loss_p_n(p,label,weight=0.1)\n",
    "        \n",
    "        loss2_n = loss_p(nc1*nc2, (1-label))\n",
    "        loss2_g = loss_p_n(1-torch.sum(c1*c2,dim=1),label,weight=0.1)\n",
    "        loss2 = loss2_n*0.1+loss2_g\n",
    "\n",
    "        loss = (loss1+loss2)*100\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "        loss_mean.append(loss.item())\n",
    "        loss_mean_1.append(loss1.item())\n",
    "        loss_mean_2.append(loss2.item())\n",
    "                \n",
    "        if (iter_+1)%2 ==0:\n",
    "            print('******************')\n",
    "            print()\n",
    "            print('Total loss: ',round(np.mean(loss_mean),5))\n",
    "            print('Change loss: ',round(np.mean(loss_mean_1),5))\n",
    "            print('Trend loss: ',round(np.mean(loss_mean_2),5))\n",
    "            print('******************')\n",
    "            loss_sum.append(np.mean(loss_mean))\n",
    "            loss_mean = []\n",
    "            loss_mean_1 = []\n",
    "            loss_mean_2 = []\n",
    "            loss_mean_3 = []\n",
    "    try:\n",
    "        trend_test()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743b6ba-798e-466e-af5a-c233f11640ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_dict = Load_Weight_FordataParallel(torch.load(Log_path+'Best_model.pth'),need_dataparallel=1)\n",
    "model.load_state_dict(state_dict)\n",
    "test_model(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6e1a3-df96-4fbc-8a27-371f062f4f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trend_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8af526b5-b6ce-4e9a-8b3f-c2b3a669ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(3,2,trend_num=trend_num)\n",
    "# model = nn.DataParallel(model)\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8bd65b2-31e9-4d11-a4ec-67325adb010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_save(x,**kwargs):\n",
    "    plt.figure(dpi=100)\n",
    "    plt.axis('off')\n",
    "    plt.imsave(arr=x,**kwargs)\n",
    "#     plt.imshow(x,**kwargs)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7161517-6472-4bbc-bf98-a7698332b660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = ['black', 'deepskyblue', 'white','red'] \n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "\n",
    "test_batch_size=1\n",
    "\n",
    "test_data = d.Dataset(TRAIN_DATA_PATH, TEST_LABEL_PATH,\n",
    "                        TEST_TXT_PATH,'test', transform=False)\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch_size,\n",
    "                            shuffle= False, num_workers= 8, pin_memory= True)\n",
    "\n",
    "train_data = d.Dataset(TRAIN_DATA_PATH, TRAIN_LABEL_PATH,\n",
    "                            TRAIN_TXT_PATH,'train',transform=False)\n",
    "train_loader = DataLoader(train_data, batch_size=test_batch_size,\n",
    "                             shuffle= True, num_workers= 8, pin_memory= True)\n",
    "\n",
    "for iter_, (i1,i2,label,file_name,mask) in enumerate(tqdm(test_loader)):\n",
    "    i1,i2,label = i1.cuda(),i2.cuda(),label.cuda()\n",
    "    with torch.no_grad():\n",
    "        p,c1,c2 = model(i1,i2)\n",
    "        c1_,c2_ = torch.max(c1,dim=1)[1],torch.max(c2,dim=1)[1]\n",
    "    \n",
    "    index=0\n",
    "    save_path = Log_path+'save_pic/'+str(iter_)+'/'\n",
    "    if 1-os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    i_name = file_name[index].split('/')[-1]\n",
    "    print(i_name)\n",
    "    # plot(plt.imread('/home/amax/yyq/Dataset/SECOND/test/label_trend/'+i_name)*255,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "    # plot(c1_[index].cpu()+c2_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "\n",
    "    I1 = i1[index].permute(1,2,0).cpu()+0.5\n",
    "    I2 = i2[index].permute(1,2,0).cpu()+0.5\n",
    "    Label = label[index].detach().cpu()\n",
    "\n",
    "    # plot(I1*Label.unsqueeze(2))\n",
    "    # plot(I2*Label.unsqueeze(2))\n",
    "\n",
    "\n",
    "    t1_semantic, t2_semantic = c1_[index], c2_[index]\n",
    "\n",
    "    appear = ((t2_semantic-t1_semantic)==t2_semantic)*(t2_semantic!=0).int()\n",
    "    disappear = ((t1_semantic-t2_semantic)==t1_semantic)*(t1_semantic!=0).int()\n",
    "    transform = ((t2_semantic!=0).int())*((t1_semantic!=0).int())\n",
    "    trend_map = (appear+disappear*2+transform*3).cpu().numpy()\n",
    "    print('predicted_trend_map')\n",
    "#     plot(trend_map,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "    plot_save(trend_map,vmin=0,vmax=trend_num,cmap=cmap,fname=save_path+'Trend_P.png')\n",
    "    \n",
    "    trend_name = file_name[0].split('/')[-1].split('.')[0]+'.npy'\n",
    "    label_trend_path = os.path.join(t_label_path,trend_name)\n",
    "    label_trend = np.load(label_trend_path)\n",
    "    print('label_trend_map')\n",
    "#     plot(label_trend,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "    plot_save(label_trend,vmin=0,vmax=trend_num,cmap=cmap,fname=save_path+'Trend_GT.png')\n",
    "\n",
    "#     plot(i1[index].permute(1,2,0).cpu()+0.5)\n",
    "#     plot(i2[index].permute(1,2,0).cpu()+0.5)\n",
    "#     plot((p[index].detach().cpu()>0.5).int())\n",
    "              \n",
    "    plot_save(i1[index].permute(1,2,0).cpu().numpy()+0.5,fname=save_path+'T1.png')\n",
    "    plot_save(i2[index].permute(1,2,0).cpu().numpy()+0.5,fname=save_path+'T2.png')\n",
    "    plot_save((p[index].detach().cpu().numpy()>0.5).astype(int),fname=save_path+'P.png')\n",
    "\n",
    "    print(\"label\")\n",
    "#     plot(label[index].detach().cpu(),interpolation=None,cmap='gray')\n",
    "    plot_save(label[index].detach().cpu().numpy(),cmap='gray',fname=save_path+'GT.png')\n",
    "              \n",
    "    print('**********')\n",
    "\n",
    "#     plot(torch.sum(c1[index,1:],dim=0).detach().cpu())\n",
    "#     plot(torch.sum(c2[index,1:],dim=0).detach().cpu())\n",
    "    plot_save(torch.sum(c1[index,1:],dim=0).detach().cpu().numpy(),fname=save_path+'Trend_T1.png')\n",
    "    plot_save(torch.sum(c2[index,1:],dim=0).detach().cpu().numpy(),fname=save_path+'Trend_T2.png')\n",
    "    # plot(c1_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "    # plot(c2_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961660c5-d0f6-4be9-8253-a8331589acae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e777059-a3d9-4c47-9d6c-5563625e41de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d093fcd-0e90-4b75-b9db-f33c4559dddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colors = ['black', 'deepskyblue', 'white','red'] \n",
    "# cmap = mpl.colors.ListedColormap(colors)\n",
    "\n",
    "# test_batch_size=1\n",
    "\n",
    "# test_data = d.Dataset(TEST_DATA_PATH, TEST_LABEL_PATH,\n",
    "#                         TEST_TXT_PATH,'test', transform=False)\n",
    "# test_loader = DataLoader(test_data, batch_size=test_batch_size,\n",
    "#                             shuffle= False, num_workers= 8, pin_memory= True)\n",
    "\n",
    "# select_index = 0\n",
    "\n",
    "# for iter_, (i1,i2,label,file_name,mask) in enumerate(tqdm(test_loader)):\n",
    "#     if iter_ == select_index:\n",
    "#         i1,i2,label = i1.cuda(),i2.cuda(),label.cuda()\n",
    "#         with torch.no_grad():\n",
    "#             p,c1,c2 = model(i1,i2)\n",
    "#             c1_,c2_ = torch.max(c1,dim=1)[1],torch.max(c2,dim=1)[1]\n",
    "#         break\n",
    "#     else:\n",
    "#         continue\n",
    "        \n",
    "# index=0\n",
    "\n",
    "# i_name = file_name[index].split('/')[-1]\n",
    "# print(i_name)\n",
    "# # plot(plt.imread('/home/amax/yyq/Dataset/SECOND/test/label_trend/'+i_name)*255,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "# # plot(c1_[index].cpu()+c2_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "\n",
    "# I1 = i1[index].permute(1,2,0).cpu()+0.5\n",
    "# I2 = i2[index].permute(1,2,0).cpu()+0.5\n",
    "# Label = label[index].detach().cpu()\n",
    "\n",
    "# # plot(I1*Label.unsqueeze(2))\n",
    "# # plot(I2*Label.unsqueeze(2))\n",
    "\n",
    "\n",
    "# t1_semantic, t2_semantic = c1_[index], c2_[index]\n",
    "\n",
    "# appear = ((t2_semantic-t1_semantic)==t2_semantic)*(t2_semantic!=0).int()\n",
    "# disappear = ((t1_semantic-t2_semantic)==t1_semantic)*(t1_semantic!=0).int()\n",
    "# transform = ((t2_semantic!=0).int())*((t1_semantic!=0).int())\n",
    "# trend_map = (appear+disappear*2+transform*3).cpu()\n",
    "# print('predicted_trend_map')\n",
    "# plot(trend_map,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "\n",
    "# trend_name = file_name[0].split('/')[-1].split('.')[0]+'.npy'\n",
    "# label_trend_path = os.path.join(t_label_path,trend_name)\n",
    "# label_trend = np.load(label_trend_path)\n",
    "# print('label_trend_map')\n",
    "# plot(label_trend,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "\n",
    "\n",
    "# plot(i1[index].permute(1,2,0).cpu()+0.5)\n",
    "# plot(i2[index].permute(1,2,0).cpu()+0.5)\n",
    "# plot((p[index].detach().cpu()>0.5).int())\n",
    "# # t_p = ((1-torch.sum(c1*c2,dim=1))>0.5)\n",
    "# # plot((t_p[index].detach().cpu()>0.5).int())\n",
    "\n",
    "# print(\"label\")\n",
    "# plot(label[index].detach().cpu(),interpolation=None,cmap='gray')\n",
    "\n",
    "# print('**********')\n",
    "\n",
    "# # plot(c1[index,0].detach().cpu())\n",
    "# # plot(c2[index,0].detach().cpu())\n",
    "# plot(torch.sum(c1[index,1:],dim=0).detach().cpu())\n",
    "# plot(torch.sum(c2[index,1:],dim=0).detach().cpu())\n",
    "# # plot(c1_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "# # plot(c2_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab9b378d-ab7f-41d2-b933-7c8c2a84fa53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index=0\n",
    "\n",
    "# i_name = file_name[index].split('/')[-1]\n",
    "# print(i_name)\n",
    "# # plot(plt.imread('/home/amax/yyq/Dataset/SECOND/test/label_trend/'+i_name)*255,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "# # plot(c1_[index].cpu()+c2_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "\n",
    "# I1 = i1[index].permute(1,2,0).cpu()+0.5\n",
    "# I2 = i2[index].permute(1,2,0).cpu()+0.5\n",
    "# Label = label[index].detach().cpu()\n",
    "\n",
    "# plot(I1*Label.unsqueeze(2))\n",
    "# plot(I2*Label.unsqueeze(2))\n",
    "\n",
    "\n",
    "# t1_semantic, t2_semantic = c1_[index], c2_[index]\n",
    "\n",
    "# appear = ((t2_semantic-t1_semantic)==t2_semantic)*(t2_semantic!=0).int()\n",
    "# disappear = ((t1_semantic-t2_semantic)==t1_semantic)*(t1_semantic!=0).int()\n",
    "# transform = (t1_semantic!=t2_semantic)*((t2_semantic!=0).int())*((t1_semantic!=0).int())\n",
    "# trend_map = (appear+disappear*2+transform*3).cpu()\n",
    "# plot(trend_map,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "\n",
    "# trend_name = file_name[0].split('/')[-1].split('.')[0]+'.npy'\n",
    "# label_trend_path = os.path.join(t_label_path,trend_name)\n",
    "# label_trend = np.load(label_trend_path)\n",
    "# plot(label_trend,vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "\n",
    "\n",
    "# plot(i1[index].permute(1,2,0).cpu()+0.5)\n",
    "# plot(i2[index].permute(1,2,0).cpu()+0.5)\n",
    "# plot((p[index].detach().cpu()>0.5).int())\n",
    "# t_p = ((1-torch.sum(c1*c2,dim=1))>0.5)\n",
    "# plot((t_p[index].detach().cpu()>0.5).int())\n",
    "\n",
    "# print(\"label\")\n",
    "# plot(label[index].detach().cpu(),interpolation=None)\n",
    "\n",
    "# print('**********')\n",
    "\n",
    "# plot(c1[index,0].detach().cpu())\n",
    "# plot(c2[index,0].detach().cpu())\n",
    "# plot(torch.sum(c1[index,1:],dim=0).detach().cpu())\n",
    "# plot(torch.sum(c2[index,1:],dim=0).detach().cpu())\n",
    "# plot(c1_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')\n",
    "# plot(c2_[index].cpu(),vmin=0,vmax=trend_num,cmap=cmap,interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61d37c11-be29-4289-be2b-5abfdc517949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 337622, 2: 7977, 1: 1})\n",
      "Counter({0: 335798, 1: 8749, 2: 1053})\n"
     ]
    }
   ],
   "source": [
    "xx = (list(c1_[index].cpu().detach().view(-1).numpy()))\n",
    "print(Counter(xx))\n",
    "xx = (list(c2_[index].cpu().detach().view(-1).numpy()))\n",
    "print(Counter(xx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
